{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image==0.16.2 in c:\\users\\rashe\\anaconda3\\envs\\python37\\lib\\site-packages (0.16.2)\n",
      "Requirement already satisfied: pillow>=4.3.0 in c:\\users\\rashe\\anaconda3\\envs\\python37\\lib\\site-packages (from scikit-image==0.16.2) (9.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.0 in c:\\users\\rashe\\anaconda3\\envs\\python37\\lib\\site-packages (from scikit-image==0.16.2) (1.7.3)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\rashe\\anaconda3\\envs\\python37\\lib\\site-packages (from scikit-image==0.16.2) (2.6.3)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in c:\\users\\rashe\\anaconda3\\envs\\python37\\lib\\site-packages (from scikit-image==0.16.2) (1.3.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\rashe\\anaconda3\\envs\\python37\\lib\\site-packages (from scikit-image==0.16.2) (3.5.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\rashe\\anaconda3\\envs\\python37\\lib\\site-packages (from scikit-image==0.16.2) (2.16.1)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\rashe\\anaconda3\\envs\\python37\\lib\\site-packages (from imageio>=2.3.0->scikit-image==0.16.2) (1.21.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\rashe\\anaconda3\\envs\\python37\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (3.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rashe\\anaconda3\\envs\\python37\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rashe\\anaconda3\\envs\\python37\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (1.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rashe\\anaconda3\\envs\\python37\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (4.31.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rashe\\anaconda3\\envs\\python37\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rashe\\anaconda3\\envs\\python37\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (0.11.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rashe\\anaconda3\\envs\\python37\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (3.10.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rashe\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-image==0.16.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.0.8\n",
      "  Downloading Keras-2.0.8-py2.py3-none-any.whl (276 kB)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in c:\\users\\rashe\\anaconda3\\lib\\site-packages (from keras==2.0.8) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in c:\\users\\rashe\\anaconda3\\lib\\site-packages (from keras==2.0.8) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.14 in c:\\users\\rashe\\anaconda3\\lib\\site-packages (from keras==2.0.8) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in c:\\users\\rashe\\anaconda3\\lib\\site-packages (from keras==2.0.8) (1.22.3)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.2.5\n",
      "    Uninstalling Keras-2.2.5:\n",
      "      Successfully uninstalled Keras-2.2.5\n",
      "Successfully installed keras-2.0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: tensorflow 2.8.0 has requirement keras<2.9,>=2.8.0rc0, but you'll have keras 2.0.8 which is incompatible.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashe\\anaconda3\\envs\\python3_7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rashe\\anaconda3\\envs\\python3_7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rashe\\anaconda3\\envs\\python3_7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rashe\\anaconda3\\envs\\python3_7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rashe\\anaconda3\\envs\\python3_7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rashe\\anaconda3\\envs\\python3_7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import cv2\n",
    "from mrcnn.visualize import display_instances\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = \"C:/Users/rashe/Desktop/Paprika\"\n",
    "\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "# Path to trained weights file\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConfig(Config):\n",
    "    \"\"\"Configuration for training on the custom  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"paprika\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + phone,laptop and mobile\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 5\n",
    "\n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: C:/Users/rashe/Desktop/Paprika\\logs\\paprika20220319T0014\\mask_rcnn_paprika_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "#  Dataset\n",
    "\n",
    "\n",
    "class PaprikaDataset(utils.Dataset):\n",
    "\n",
    "    def load_custom(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the Dog-Cat dataset.\n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "        # Add classes. We have only one class to add.\n",
    "        self.add_class(\"paprika\", 1, \"paprika\")\n",
    "\n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        # Load annotations\n",
    "        # VGG Image Annotator saves each image in the form:\n",
    "        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n",
    "        #   'regions': {\n",
    "        #       '0': {\n",
    "        #           'region_attributes': {},\n",
    "        #           'shape_attributes': {\n",
    "        #               'all_points_x': [...],\n",
    "        #               'all_points_y': [...],\n",
    "        #               'name': 'polygon'}},\n",
    "        #       ... more regions ...\n",
    "        #   },\n",
    "        #   'size': 100202\n",
    "        # }\n",
    "        # We mostly care about the x and y coordinates of each region\n",
    "        annotations1 = json.load(\n",
    "            open(os.path.join('C:/Users/rashe/Desktop/Paprika/dataset/train', \"via_region_data.json\")))\n",
    "        # annotations1 = json.load(open(os.path.join('/content/dataset/train', \"via_project.json\")))\n",
    "        # print(annotations1)\n",
    "        annotations = list(annotations1.values())  # don't need the dict keys\n",
    "\n",
    "        # The VIA tool saves images in the JSON even if they don't have any\n",
    "        # annotations. Skip unannotated images.\n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "      # Add images\n",
    "        for a in annotations:\n",
    "            # Get the x, y coordinaets of points of the polygons that make up\n",
    "            # the outline of each object instance. These are stores in the\n",
    "            # shape_attributes (see json format above)\n",
    "            # The if condition is needed to support VIA versions 1.x and 2.x.\n",
    "            if type(a['regions']) is dict:\n",
    "                polygons = [r['shape_attributes']\n",
    "                            for r in a['regions'].values()]\n",
    "            else:\n",
    "                polygons = [r['shape_attributes'] for r in a['regions']]\n",
    "\n",
    "            # load_mask() needs the image size to convert polygons to masks.\n",
    "            # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
    "            # the image. This is only managable since the dataset is tiny.\n",
    "            image_path = os.path.join('C:/Users/rashe/Desktop/Paprika/dataset/train', a['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            self.add_image(\n",
    "                \"paprika\",\n",
    "                image_id=a['filename'],  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                polygons=polygons)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a paprika dataset image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"paprika\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] != \"paprika\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # num_ids = info['num_ids']\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "######################################################################################################\n",
    "#             # In case the data sets conatins overflowing coordinate, Run the following codes form Here\n",
    "#             print(\"mask.shape, min(mask),max(mask): {}, {},{}\".format(\n",
    "#                 mask.shape, np.min(mask), np.max(mask)))\n",
    "#             print(\"rr.shape, min(rr),max(rr): {}, {},{}\".format(\n",
    "#                 rr.shape, np.min(rr), np.max(rr)))\n",
    "#             print(\"cc.shape, min(cc),max(cc): {}, {},{}\".format(\n",
    "#                 cc.shape, np.min(cc), np.max(cc)))\n",
    "\n",
    "#             # Note that this modifies the existing array arr, instead of creating a result array\n",
    "#             # Ref: https://stackoverflow.com/questions/19666626/replace-all-elements-of-python-numpy-array-that-are-greater-than-some-value\n",
    "#             rr[rr > mask.shape[0]-1] = mask.shape[0]-1\n",
    "#             cc[cc > mask.shape[1]-1] = mask.shape[1]-1\n",
    "\n",
    "#             print(\"After fixing the dirt mask, new values:\")\n",
    "#             print(\"rr.shape, min(rr),max(rr): {}, {},{}\".format(\n",
    "#                 rr.shape, np.min(rr), np.max(rr)))\n",
    "#             print(\"cc.shape, min(cc),max(cc): {}, {},{}\".format(\n",
    "#                 cc.shape, np.min(cc), np.max(cc)))\n",
    "\n",
    "#             # To here\n",
    "####################################################################################################################\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        # Map class names to class IDs.\n",
    "        # num_ids = np.array(num_ids, dtype=np.int32)\n",
    "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"paprika\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\n",
    "\n",
    "\n",
    "def train(model):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Training dataset.\n",
    "    dataset_train = PaprikaDataset()\n",
    "    dataset_train.load_custom(\"C:/Users/rashe/Desktop/Paprika/dataset\", \"train\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = PaprikaDataset()\n",
    "    dataset_val.load_custom(\"C:/Users/rashe/Desktop/Paprika/dataset\", \"val\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    # *** This training schedule is an example. Update to your needs ***\n",
    "    # Since we're using a very small dataset, and starting from\n",
    "    # COCO trained weights, we don't need to train too long. Also,\n",
    "    # no need to train all layers, just the heads should do it.\n",
    "    print(\"Training network heads\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=2,\n",
    "                layers='heads')\n",
    "\n",
    "\n",
    "config = CustomConfig()\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=DEFAULT_LOGS_DIR)\n",
    "\n",
    "\n",
    "weights_path = COCO_WEIGHTS_PATH\n",
    "# Download weights file\n",
    "if not os.path.exists(weights_path):\n",
    "    utils.download_trained_weights(weights_path)\n",
    "\n",
    "model.load_weights(weights_path, by_name=True, exclude=[\n",
    "    \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "    \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "train(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
